\chapter{The Visual Profiler Backend}
The backend is the part of the profiler resposible for collecting the data from the profiled application and for sending them to the analitic part of the Visual Profiler frontend. There are many requirement for a profiling backend to fulfill, such as speed, mutli-threadinng, correctness, low memory consumption and others. In this chapter, we will introduce the profiling modes we chose to implement and review the inner implementation of the backend and desing decision we had to make.

\section{Choice of the implentation strategy and the profiling modes}
Based on the analysis of the profiling modes on the .NET platform in the chapter \ref{chapPerProfOnDotNet}. We made a decision to use the profiling API as the base for our own profiler before the implementing everything from scratch. The profiling API offers a 	 matured API with intrinsic support of all .NET features. This helps to avoid many unnecessary implementation problems that could be encountere during an implementation of a .NET profiler entirely from beginning.

In the abstract of the thesis we have committed ourself to create a method granularity profiler supporting two distinct profiling modes for the .NET.

The choice of the sampling profiling mode was straightforward because of its stochastic nature in that it completely differs from the other two modes. 

On the other hand, the difference between the tracing and the intrumentation profiling is not that vast. They both measure exact results and put similar overhead on the profiling. However, the selected method granurality makes them both even more comparable from user's point of view. They both have their implementation pitfall and neither of them would be easier to progam that the other. In the end, we opted for the tracing profiling mode since it does not require any changes to target assemblies.

\section{Software architecture of the backend }
The backend runs in two process. The first process, written in C++ and called the Visual Profiler Backend, is the actual profiled application with the hosted profiler DLL that is loaded by the CLR and accessed by the COM interface, as described in the chapter \ref{chapPerProfOnDotNet}. The sampling and tracing profiliers are implemented as distinct COM CoClasses and only one of them can run at a time. The CoClasses share the common code base for the profiled data collection and the interprocess communication with the managed code.

The second process is programmed in C\# and called the Visual Profiler Access. It starts the profiled application, written in C++, with the desired profiling mode in a separate process, initialize the interprocess communication for transferring the profiling data and is responsible for their processing so they can be later used by an analystic and UI frontend.

The whole relation is shown on the figure \ref{fig:04softwareArchitecture}.

\begin{figure}
	\centering
		\includegraphics[scale=1]{\imagePath 04softwareArchitecture.png}
		\caption{The backend's architecture}
	\label{fig:04softwareArchitecture}
\end{figure}


\subsection{The Visual Profiler Backend }
In this part are the both chosen profiling mode implemented. It also contains bunch of supporting classes for handling metadata information for methods, classes, modules and assemblies, for caching the profiling intermediate results and for serializing the results and transmitting them over IPC to the Visual Profiler Access. The Active Template Library (ATL) framework from Microsoft is used to simplify programing of the Component Object Model (COM) in C++

Let us now introduce you the inner structure and rough outline.

\subsubsection{Implentations of the \textit{ICorProfilerCallback3 } interface}
The \textit{ICorProfilerCallback3} interface is the center point of the profiling API. With its 80 methods it is a little bit unpractical to implement it, mainly because only a handful of the method is usualy made use of. For that reason we created a default class \textit{CorProfilerCallbackBase} as depicted on the figure \ref{fig:04ProfilerCallbacks}. This provides empty implementation of every methods of the interface and derived classes can only override desired methods. This idea makes it easier to have clearly arranged classes, the clean code rules.

\begin{figure}
	\centering
		\includegraphics[scale=1]{\imagePath 04ProfilerCallbacks.png}
		\caption{Implentations of the \textit{ICorProfilerCallback3} interface}
	\label{fig:04ProfilerCallbacks}
\end{figure}

$$The both classes, the \textit{TracingProfiler} and the \textit{SamplingProfiler}, override the \textit{Initialize}, \textit{ThreadCreated} and \textit{ThreadDestroyed}. This
$$
\subsubsection*{The \textit{TracingProfiler} class}
This class is home for the tracing profiler mode implementation, the figure \ref{fig:04ProfilerCallbacks}. It starts its lifetime by running the IPC with the Visual Profiler Access on a separate thread in the \textit{Constructor()} method. After that, the \textit{Initialize()} method is invoked by the CLR and passed a pointer to the \textit{ICallProfilerInfo3} interface. Here registers the profiler the function ID mapper (more detail later in this subsection), the function enter/leave, the thread created/destroyed and the exception events notifications. At this point is everything set up and the profiled application starts running.

During the profiling session there is a need to trace the method enter and leave notifications for every managed thread simultaneously. This is a demanding task if you take in account the every single call to and return from a managed method is augmented by overhead of this notifications. 

Our first approach to store the collected profiling information was to push the data, a function ids, into an enter stack and a leave stack. Every managed had its own private enter and leave stacks. All stacks were saved by the corresponding thread ids in a common hash table. During the processin of a funtion enter or leave notification the hash table had to be searched. This created a potential race condition (inserting a new thread to hash table and reading from it at the same time). So the critical section had to be added to access the hash table.

That was fairly easy to implement and did indeed worked. However, performed not very well. Firstly, it used so much memory that after tens of seconds the application memory working set reached hunderts of mega bytes. Secondly, the syncronized hash table lookups slowed down the application. The profiled application was running approximately 50 times slower! (according to the rough duration messurements in the profiled application). It was clearly unacceptable. A better solution had to be found. 

Subsequently, we realized that an union of snapshots of thread's call stacks forms a call tree as depicted on the figure \ref{fig:04PrimitiveCallTree}.


\begin{figure}
	\centering
		\includegraphics[scale=1]{\imagePath 04PrimitiveCallTree.png}
		\caption{Union of thread's call stack snapshots forming a call tree. A very simple example: A calls  B, B calls C, C returns to B, B calls D, D returs to B, B return to A }
	\label{fig:04PrimitiveCallTree}
\end{figure}

The \textit{TracingCallTree} class was created based on the idea.
A simplified representation of the TracingCallTree class is depicted on the figure \ref{fig:04TracingCallTreeActiveElem}. Every tree element (class TracingCallTreeElem) contains commulative profiling results such as the number of the enter and leave, time related data and some other auxiliary data. The object of the TracingCallTree class contains an active element pointer and a root pointer. The active element pointer points to an element representing a currently executing function and the root element pointer represents the top most method, e.g. the Main method. 

When a method calls another method, its tree child, the active element pointer only moves to the child and the profiling data is modified. This solution performs very well. Even a huge call tree takes negligible amount of memory and the transition are very quick. 

The other improvement was in using a thread local storage of managed threads for storing a reference to the call trees. Thanks to this the lookup in the call tree hash table can be avoided in thread safe manners with significant speed gain. 

The change from a stack to a call tree and usage of the thread local storage brought together a huge speed and memory performance enhancement. The profiled application runs now 4 times slower, compared to 50 times before, than the without profiling. This slowdown is valid only for the unoptimized build of the profiler (debug settings), the optimized version performs even better. 

Let us move on with the profilier's activity. The profiler receives a notification from the CLR whenever a new managed thread is created - via the method \textit{ThreadCreated}. The notification executes within the context of the newly created thread. The tracing profiler registers the thread id and associates with it an instance of the \textit{TracingCallTree} class. Such an association is saved into a hash table, represented by C++ \textit{std::map}, under the thread id key. The reference to the \textit{TracingCallTree} object is stored into the thread local storage in order to avoid repetitive search in the hash table by every single enter/leave notification.

And then a managed method in the profiling appliction is about to be entered. But before it is actually entered the CLR gives a chance to the tracing profiler to express its interest in this particular methods. The CLR invokes the FunctionIdMapper method and passes it a function id (type FunctionID) of the method. The profiler caches the method's metadata (the name, the declaring...) obtained by the function id and if the method is from an assembly with enabled profiling (explained later) the profiler express its interest in receiving the enter/leave notifications for the method,  or hooks to it, by setting an output parameter of the FunctionIdMapper to \textit{true} value. The function id mapping occurrs only once for every managed method.

If a hooked managed method is being entered the CLR call the profilier's function-enter handler and passes to it the same function id as to the FunctionIdMapper method. This notification is very performance sensitive (very repetitiv) and therefore the function-enter handler is declared with the naked attribute (\textit{\_declspec(naked)}), the compiler generates code without prolog and epilog code. We had to write own prolog/epilog code sequences using inline assembler code to call yet another function that makes a downward transition on the thread's tracing call tree.

When a function is being left the profiler's function-leave handler is called and again receives as an input parameter the function id. The function-leave handler has to be declared with the naked attribute as well. It just calls another function to make a upward transition on the thread's tracing call tree.

If a thread of the profiled application ends its execution without any exception the CLR call the ThreadDestroyed method and lets the tracing profiler to do some book-keeping and close the corresponding tracing call tree.

If an exception occurs on a thread then a search for a \textit{catch} clause begins by walking up a thread's call stack. The CLR the ExceptionSearchFunctionEnter invokes for every searched function on the thread's call stack till it find the matching \textit{catch} clause and calls the ExceptionSearchCatcherFound funtion. The tracing profiler uses this exception handling mechanism to transition upwards the corresponding tracing call tree. If the \textit{catch} were not found the profiled application would crash due to an unhandled exception.
 
After the profiling application exitted, the IPC is ended and the profiling session is over.



\begin{figure}
	\centering
		\includegraphics[scale=1.3]{\imagePath 04TracingCallTreeActiveElem.png}
		\caption{A simplified representation of the TracingCallTree class. The active element pointer points to the currently executing function element with the call tree hierarchy. }
	\label{fig:04TracingCallTreeActiveElem}
\end{figure}













\begin{figure}
	\centering
		\includegraphics[scale=0.6,angle=90]{\imagePath 04backendStructure.png}
		\caption{The hierarchy of the call tree classes used to trace the collected profiling data.}
	\label{fig:04backendStructure}
\end{figure}

